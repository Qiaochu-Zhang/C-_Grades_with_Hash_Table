{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMi10DpUUzLioXEdVTR1aVE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Qiaochu-Zhang/C-_Grades_with_Hash_Table/blob/main/denseNet1023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3pQ7RInQBa1",
        "outputId": "02e4a468-ef40-41f7-86ad-af8960cf9e71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln7sN3vTkX8M",
        "outputId": "5a8053ab-4e3f-4fbe-cbab-dc3b87dc7be1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n",
        "!pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHJf7JdDkvUp",
        "outputId": "bb7cac5b-cc66-4626-dda7-b0744ec6f390"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import cv2\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "import random\n",
        "\n",
        "# 检查是否有GPU可用\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 设置随机种子\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# 自定义数据集类\n",
        "class NoiseDataset(Dataset):\n",
        "    def __init__(self, image_folder, label):\n",
        "        self.image_paths = [\n",
        "            os.path.join(image_folder, img)\n",
        "            for img in os.listdir(image_folder)\n",
        "            if img.lower().endswith(('.jpg', '.jpeg'))\n",
        "        ]\n",
        "        self.image_paths = [path for path in self.image_paths if cv2.imread(path) is not None]\n",
        "        self.labels = [label] * len(self.image_paths)\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485], std=[0.229])\n",
        "        ])\n",
        "\n",
        "    def extract_noise(self, image_path):\n",
        "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        blurred = cv2.GaussianBlur(img, (5, 5), 0)\n",
        "        noise = cv2.absdiff(img, blurred)\n",
        "        return Image.fromarray(noise)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        noise_image = self.extract_noise(self.image_paths[idx])\n",
        "        img_tensor = self.transform(noise_image)\n",
        "        label = self.labels[idx]\n",
        "        return img_tensor, label\n",
        "\n",
        "# 定义数据集路径\n",
        "real_images_path = '/content/drive/MyDrive/Real'\n",
        "ai_images_path = '/content/drive/MyDrive/fake'\n",
        "\n",
        "# 加载数据集\n",
        "real_dataset = NoiseDataset(real_images_path, label=0)\n",
        "ai_dataset = NoiseDataset(ai_images_path, label=1)\n",
        "\n",
        "# 合并数据集\n",
        "full_dataset = real_dataset + ai_dataset\n",
        "\n",
        "# 划分测试集（10%）\n",
        "test_size = 0.1\n",
        "labels = [label for _, label in full_dataset]\n",
        "train_val_indices, test_indices = train_test_split(\n",
        "    range(len(full_dataset)), test_size=test_size, stratify=labels, random_state=42\n",
        ")\n",
        "\n",
        "train_val_dataset = Subset(full_dataset, train_val_indices)\n",
        "test_dataset = Subset(full_dataset, test_indices)\n",
        "\n",
        "print(f\"Training+Validation set size: {len(train_val_dataset)}\")\n",
        "print(f\"Test set size: {len(test_dataset)}\")\n",
        "\n",
        "# 定义K折交叉验证\n",
        "k_folds = 5\n",
        "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# 初始化DenseNet模型\n",
        "def initialize_densenet():\n",
        "    model = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
        "    original_conv0 = model.features.conv0\n",
        "\n",
        "    # 修改卷积层为单通道输入\n",
        "    model.features.conv0 = nn.Conv2d(\n",
        "        in_channels=1,\n",
        "        out_channels=original_conv0.out_channels,\n",
        "        kernel_size=original_conv0.kernel_size,\n",
        "        stride=original_conv0.stride,\n",
        "        padding=original_conv0.padding,\n",
        "        bias=original_conv0.bias is not None\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        model.features.conv0.weight = nn.Parameter(original_conv0.weight.sum(dim=1, keepdim=True))\n",
        "\n",
        "    # 修改分类层为2类输出\n",
        "    num_ftrs = model.classifier.in_features\n",
        "    model.classifier = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    return model.to(device)\n",
        "\n",
        "# 定义损失函数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 保存最佳模型的权重\n",
        "best_model_wts = None\n",
        "best_acc = 0.0\n",
        "\n",
        "# 开始交叉验证\n",
        "for fold, (train_ids, val_ids) in enumerate(kfold.split(train_val_indices)):\n",
        "    print(f'\\nFold {fold + 1}\\n-------------------')\n",
        "\n",
        "    # 创建训练和验证数据集\n",
        "    train_subset = Subset(train_val_dataset, train_ids)\n",
        "    val_subset = Subset(train_val_dataset, val_ids)\n",
        "\n",
        "    # 创建数据加载器\n",
        "    train_loader = DataLoader(train_subset, batch_size=8, shuffle=True)\n",
        "    val_loader = DataLoader(val_subset, batch_size=8, shuffle=False)\n",
        "\n",
        "    # 初始化模型和优化器\n",
        "    model = initialize_densenet()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "    num_epochs = 5\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for data, target in train_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "\n",
        "    # 验证模型\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in val_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            outputs = model(data)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Fold {fold + 1} Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "    # 保存表现最佳的模型\n",
        "    if accuracy > best_acc:\n",
        "        best_acc = accuracy\n",
        "        best_model_wts = model.state_dict()\n",
        "\n",
        "# 加载最佳模型的权重\n",
        "model.load_state_dict(best_model_wts)\n",
        "\n",
        "# 在测试集上评估模型\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "test_accuracy = 100 * correct / total\n",
        "print(f'\\nTest Accuracy: {test_accuracy:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNVbwOotk1eB",
        "outputId": "ab1749d9-7402-4897-9312-0f99aa23cfeb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Training+Validation set size: 268\n",
            "Test set size: 30\n",
            "\n",
            "Fold 1\n",
            "-------------------\n",
            "Epoch [1/5], Loss: 0.6444\n",
            "Epoch [2/5], Loss: 0.2857\n",
            "Epoch [3/5], Loss: 0.1300\n",
            "Epoch [4/5], Loss: 0.1454\n",
            "Epoch [5/5], Loss: 0.1320\n",
            "Fold 1 Accuracy: 85.19%\n",
            "\n",
            "Fold 2\n",
            "-------------------\n",
            "Epoch [1/5], Loss: 0.5523\n",
            "Epoch [2/5], Loss: 0.2702\n",
            "Epoch [3/5], Loss: 0.1706\n",
            "Epoch [4/5], Loss: 0.1693\n",
            "Epoch [5/5], Loss: 0.1224\n",
            "Fold 2 Accuracy: 79.63%\n",
            "\n",
            "Fold 3\n",
            "-------------------\n",
            "Epoch [1/5], Loss: 0.6316\n",
            "Epoch [2/5], Loss: 0.2685\n",
            "Epoch [3/5], Loss: 0.1426\n",
            "Epoch [4/5], Loss: 0.0589\n",
            "Epoch [5/5], Loss: 0.0380\n",
            "Fold 3 Accuracy: 85.19%\n",
            "\n",
            "Fold 4\n",
            "-------------------\n",
            "Epoch [1/5], Loss: 0.6393\n",
            "Epoch [2/5], Loss: 0.2956\n",
            "Epoch [3/5], Loss: 0.1443\n",
            "Epoch [4/5], Loss: 0.1505\n",
            "Epoch [5/5], Loss: 0.1126\n",
            "Fold 4 Accuracy: 92.45%\n",
            "\n",
            "Fold 5\n",
            "-------------------\n",
            "Epoch [1/5], Loss: 0.5825\n",
            "Epoch [2/5], Loss: 0.2721\n",
            "Epoch [3/5], Loss: 0.1872\n",
            "Epoch [4/5], Loss: 0.1549\n",
            "Epoch [5/5], Loss: 0.0936\n",
            "Fold 5 Accuracy: 75.47%\n",
            "\n",
            "Test Accuracy: 73.33%\n"
          ]
        }
      ]
    }
  ]
}