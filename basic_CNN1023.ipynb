{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Qiaochu-Zhang/C-_Grades_with_Hash_Table/blob/main/basic_CNN1023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ovp005oodj0M",
        "outputId": "bb38efb5-3ed4-4092-8086-6606aa964ded"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNPik_7reJED",
        "outputId": "8e8a7eac-907b-4925-9c23-b85c075d745b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTTYYcuVeYNr",
        "outputId": "d0207545-2af8-4c02-b59a-c5e186288738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW9h29sPeesR",
        "outputId": "b85611f8-39e4-4550-eee4-b83b6bb05617"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Training+Validation set size: 268\n",
            "Test set size: 30\n",
            "\n",
            "Fold 1\n",
            "--------------------------------\n",
            "Epoch [1/5], Loss: 0.7080\n",
            "Epoch [2/5], Loss: 0.6940\n",
            "Epoch [3/5], Loss: 0.6911\n",
            "Epoch [4/5], Loss: 0.6902\n",
            "Epoch [5/5], Loss: 0.6801\n",
            "Fold 1 Accuracy: 64.81%\n",
            "\n",
            "Fold 2\n",
            "--------------------------------\n",
            "Epoch [1/5], Loss: 0.6985\n",
            "Epoch [2/5], Loss: 0.6945\n",
            "Epoch [3/5], Loss: 0.6925\n",
            "Epoch [4/5], Loss: 0.6928\n",
            "Epoch [5/5], Loss: 0.6927\n",
            "Fold 2 Accuracy: 42.59%\n",
            "\n",
            "Fold 3\n",
            "--------------------------------\n",
            "Epoch [1/5], Loss: 0.7064\n",
            "Epoch [2/5], Loss: 0.6935\n",
            "Epoch [3/5], Loss: 0.6949\n",
            "Epoch [4/5], Loss: 0.6916\n",
            "Epoch [5/5], Loss: 0.6981\n",
            "Fold 3 Accuracy: 62.96%\n",
            "\n",
            "Fold 4\n",
            "--------------------------------\n",
            "Epoch [1/5], Loss: 0.7000\n",
            "Epoch [2/5], Loss: 0.6988\n",
            "Epoch [3/5], Loss: 0.6938\n",
            "Epoch [4/5], Loss: 0.6920\n",
            "Epoch [5/5], Loss: 0.6621\n",
            "Fold 4 Accuracy: 62.26%\n",
            "\n",
            "Fold 5\n",
            "--------------------------------\n",
            "Epoch [1/5], Loss: 0.7008\n",
            "Epoch [2/5], Loss: 0.6952\n",
            "Epoch [3/5], Loss: 0.6928\n",
            "Epoch [4/5], Loss: 0.6795\n",
            "Epoch [5/5], Loss: 0.6538\n",
            "Fold 5 Accuracy: 73.58%\n",
            "\n",
            "Test Accuracy: 60.00%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import cv2\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "import random\n",
        "\n",
        "# 检查是否有GPU可用\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 设置随机种子\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# 自定义数据集类，只检查 .jpg 和 .jpeg 文件\n",
        "class NoiseDataset(Dataset):\n",
        "    def __init__(self, image_folder, label):\n",
        "        self.image_paths = [\n",
        "            os.path.join(image_folder, img)\n",
        "            for img in os.listdir(image_folder)\n",
        "            if img.lower().endswith(('.jpg', '.jpeg'))\n",
        "        ]\n",
        "        # 过滤无法读取的图片路径\n",
        "        self.image_paths = [path for path in self.image_paths if cv2.imread(path) is not None]\n",
        "        self.labels = [label] * len(self.image_paths)\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((64, 64)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "    def extract_noise(self, image_path):\n",
        "        \"\"\"提取图片的噪声特征\"\"\"\n",
        "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        blurred = cv2.GaussianBlur(img, (5, 5), 0)\n",
        "        noise = cv2.absdiff(img, blurred)\n",
        "        return Image.fromarray(noise)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        noise_image = self.extract_noise(self.image_paths[idx])\n",
        "        img_tensor = self.transform(noise_image)\n",
        "        label = self.labels[idx]\n",
        "        return img_tensor, label\n",
        "\n",
        "# 定义数据集路径\n",
        "real_images_path = '/content/drive/MyDrive/Real'\n",
        "ai_images_path = '/content/drive/MyDrive/fake'\n",
        "\n",
        "# 加载数据集\n",
        "real_dataset = NoiseDataset(real_images_path, label=0)\n",
        "ai_dataset = NoiseDataset(ai_images_path, label=1)\n",
        "\n",
        "# 合并数据集\n",
        "full_dataset = real_dataset + ai_dataset\n",
        "\n",
        "# 打乱数据集并划分测试集（10%）\n",
        "test_size = 0.1\n",
        "labels = [label for _, label in full_dataset]\n",
        "train_val_indices, test_indices = train_test_split(\n",
        "    range(len(full_dataset)), test_size=test_size, stratify=labels, random_state=42\n",
        ")\n",
        "\n",
        "train_val_dataset = Subset(full_dataset, train_val_indices)\n",
        "test_dataset = Subset(full_dataset, test_indices)\n",
        "\n",
        "print(f\"Training+Validation set size: {len(train_val_dataset)}\")\n",
        "print(f\"Test set size: {len(test_dataset)}\")\n",
        "\n",
        "# 定义K折交叉验证\n",
        "k_folds = 5\n",
        "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# 定义 CNN 模型\n",
        "class NoiseCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NoiseCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(32 * 16 * 16, 128)\n",
        "        self.fc2 = nn.Linear(128, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 32 * 16 * 16)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# 保存最佳模型的权重\n",
        "best_model_wts = None\n",
        "best_acc = 0.0\n",
        "\n",
        "# 开始交叉验证\n",
        "for fold, (train_ids, val_ids) in enumerate(kfold.split(train_val_indices)):\n",
        "    print(f'\\nFold {fold + 1}')\n",
        "    print('--------------------------------')\n",
        "\n",
        "    # 定义训练和验证数据集\n",
        "    train_loader = DataLoader(\n",
        "        Subset(train_val_dataset, train_ids), batch_size=8, shuffle=True\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        Subset(train_val_dataset, val_ids), batch_size=8, shuffle=False\n",
        "    )\n",
        "\n",
        "    # 初始化模型、损失函数和优化器\n",
        "    model = NoiseCNN().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # 训练模型\n",
        "    for epoch in range(5):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for data, target in train_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        print(f'Epoch [{epoch + 1}/5], Loss: {avg_loss:.4f}')\n",
        "\n",
        "    # 验证模型\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in val_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            outputs = model(data)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Fold {fold + 1} Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "    # 保存表现最佳的模型\n",
        "    if accuracy > best_acc:\n",
        "        best_acc = accuracy\n",
        "        best_model_wts = model.state_dict()\n",
        "\n",
        "# 加载最佳模型的权重\n",
        "model.load_state_dict(best_model_wts)\n",
        "\n",
        "# 在测试集上评估模型\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "test_accuracy = 100 * correct / total\n",
        "print(f'\\nTest Accuracy: {test_accuracy:.2f}%')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOw4pZdRdrYth3m9Ff6syHe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}